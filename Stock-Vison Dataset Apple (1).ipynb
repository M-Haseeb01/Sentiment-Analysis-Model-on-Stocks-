{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f7b248-e0e0-4039-b91b-984979133e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7nca41</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Blowing versus sucking</td>\n",
       "      <td>AAPL just entered a contract to purchase 51 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585576</th>\n",
       "      <td>pq28pz</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>Today's trades.</td>\n",
       "      <td>Added to $AAPL at lows. Added to $AMD at lows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585585</th>\n",
       "      <td>pq2idf</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>Using delta to calculate an option's leverage ...</td>\n",
       "      <td>#**Introduction**\\nMaybe a lot of people use s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585608</th>\n",
       "      <td>pq3qvu</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>Small Account (scalping trader) *Weekly Update...</td>\n",
       "      <td>This is another weekly update on my small acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585955</th>\n",
       "      <td>pqkei6</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>Top technology stocks for today, part 1</td>\n",
       "      <td>Incl. ADI ADBE AVYA BKI AAPL COHU DT DQ ECOM E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404557</th>\n",
       "      <td>m8m8np</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>$TSLA Chinese military bans Tesla cars in its ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12689</th>\n",
       "      <td>9drpoq</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>Mfw TSLA is on sale and it's my time to buy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756768</th>\n",
       "      <td>zps68h</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>Options Questions Safe Haven Thread | Dec 18-2...</td>\n",
       "      <td>For the options questions you wanted to ask, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756761</th>\n",
       "      <td>zpreoo</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>morning breakdown</td>\n",
       "      <td>The S&amp;amp;P 500 futures are 0.3% above fair va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225444</th>\n",
       "      <td>l99t6r</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>GME market volatility got my account crushed F...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760097 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id stock_symbol created_utc  \\\n",
       "0       7nca41         aapl  2018-01-01   \n",
       "585576  pq28pz         aapl  2021-09-17   \n",
       "585585  pq2idf         aapl  2021-09-17   \n",
       "585608  pq3qvu         aapl  2021-09-17   \n",
       "585955  pqkei6         aapl  2021-09-18   \n",
       "...        ...          ...         ...   \n",
       "404557  m8m8np         tsla  2021-03-19   \n",
       "12689   9drpoq         tsla  2018-09-07   \n",
       "756768  zps68h         tsla  2022-12-19   \n",
       "756761  zpreoo         tsla  2022-12-19   \n",
       "225444  l99t6r         tsla  2021-01-31   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                  Blowing versus sucking   \n",
       "585576                                    Today's trades.   \n",
       "585585  Using delta to calculate an option's leverage ...   \n",
       "585608  Small Account (scalping trader) *Weekly Update...   \n",
       "585955            Top technology stocks for today, part 1   \n",
       "...                                                   ...   \n",
       "404557  $TSLA Chinese military bans Tesla cars in its ...   \n",
       "12689         Mfw TSLA is on sale and it's my time to buy   \n",
       "756768  Options Questions Safe Haven Thread | Dec 18-2...   \n",
       "756761                                  morning breakdown   \n",
       "225444  GME market volatility got my account crushed F...   \n",
       "\n",
       "                                                 selftext  \n",
       "0       AAPL just entered a contract to purchase 51 of...  \n",
       "585576  Added to $AAPL at lows. Added to $AMD at lows ...  \n",
       "585585  #**Introduction**\\nMaybe a lot of people use s...  \n",
       "585608  This is another weekly update on my small acco...  \n",
       "585955  Incl. ADI ADBE AVYA BKI AAPL COHU DT DQ ECOM E...  \n",
       "...                                                   ...  \n",
       "404557                                                NaN  \n",
       "12689                                                 NaN  \n",
       "756768  For the options questions you wanted to ask, b...  \n",
       "756761  The S&amp;P 500 futures are 0.3% above fair va...  \n",
       "225444                                                NaN  \n",
       "\n",
       "[760097 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning and merging POSTS files\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\posts.csv\")\n",
    "\n",
    "df1 = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\stock_index.csv\")\n",
    "\n",
    "#making date proper\n",
    "df1['created_utc'] = pd.to_datetime(df1['created_utc'], unit='s')\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "#merging on basis of id,time\n",
    "merged_df = pd.merge(df1, df, on=['id', 'created_utc'], how='inner')\n",
    "\n",
    "merged_df=merged_df.sort_values(by='stock_symbol')\n",
    "merged_df=merged_df.drop(columns= ['subreddit', 'author', \n",
    "        'permalink', 'url'])\n",
    "merged_df=merged_df.sort_values(by='stock_symbol')\n",
    "\n",
    "merged_df['created_utc'] = pd.to_datetime(merged_df['created_utc']).dt.date\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d16f4f7-2e9b-4b66-a819-a21ec5c072da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6412\\3179512895.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  apple_df_filtered['Date'] = pd.to_datetime(apple_df_filtered['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pq28pz</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>143.201829</td>\n",
       "      <td>143.496567</td>\n",
       "      <td>129868800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Today's trades.Added to $AAPL at lows. Added t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pq2idf</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>143.201829</td>\n",
       "      <td>143.496567</td>\n",
       "      <td>129868800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Using delta to calculate an option's leverage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pq3qvu</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>143.201829</td>\n",
       "      <td>143.496567</td>\n",
       "      <td>129868800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Small Account (scalping trader) *Weekly Update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pq5pav</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>143.201829</td>\n",
       "      <td>143.496567</td>\n",
       "      <td>129868800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Essential Properties Realty Trust Inc NYSE: EP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pq775d</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>143.201829</td>\n",
       "      <td>143.496567</td>\n",
       "      <td>129868800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Top 10 dividends survey (please read/upvote)Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21739</th>\n",
       "      <td>isj8yi</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>111.986320</td>\n",
       "      <td>113.167486</td>\n",
       "      <td>110.112074</td>\n",
       "      <td>112.611069</td>\n",
       "      <td>140150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Investing News Morning Roundup â€“ September 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21740</th>\n",
       "      <td>isjy8n</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>111.986320</td>\n",
       "      <td>113.167486</td>\n",
       "      <td>110.112074</td>\n",
       "      <td>112.611069</td>\n",
       "      <td>140150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Top 5 Things To Watch In The Stock Market This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21741</th>\n",
       "      <td>isk1j3</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>111.986320</td>\n",
       "      <td>113.167486</td>\n",
       "      <td>110.112074</td>\n",
       "      <td>112.611069</td>\n",
       "      <td>140150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Is $AAPL a good buy right now?[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21742</th>\n",
       "      <td>islhxy</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>111.986320</td>\n",
       "      <td>113.167486</td>\n",
       "      <td>110.112074</td>\n",
       "      <td>112.611069</td>\n",
       "      <td>140150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$NVDA - street's initial take on $40b ARM acqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21743</th>\n",
       "      <td>isliew</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>111.986320</td>\n",
       "      <td>113.167486</td>\n",
       "      <td>110.112074</td>\n",
       "      <td>112.611069</td>\n",
       "      <td>140150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$NVDA - street's initial take on $40b ARM acqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21744 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id stock_symbol       Date        Open        High         Low  \\\n",
       "0      pq28pz         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
       "1      pq2idf         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
       "2      pq3qvu         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
       "3      pq5pav         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
       "4      pq775d         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
       "...       ...          ...        ...         ...         ...         ...   \n",
       "21739  isj8yi         aapl 2020-09-14  111.986320  113.167486  110.112074   \n",
       "21740  isjy8n         aapl 2020-09-14  111.986320  113.167486  110.112074   \n",
       "21741  isk1j3         aapl 2020-09-14  111.986320  113.167486  110.112074   \n",
       "21742  islhxy         aapl 2020-09-14  111.986320  113.167486  110.112074   \n",
       "21743  isliew         aapl 2020-09-14  111.986320  113.167486  110.112074   \n",
       "\n",
       "            Close     Volume  Dividends  Stock Splits  \\\n",
       "0      143.496567  129868800        0.0           0.0   \n",
       "1      143.496567  129868800        0.0           0.0   \n",
       "2      143.496567  129868800        0.0           0.0   \n",
       "3      143.496567  129868800        0.0           0.0   \n",
       "4      143.496567  129868800        0.0           0.0   \n",
       "...           ...        ...        ...           ...   \n",
       "21739  112.611069  140150100        0.0           0.0   \n",
       "21740  112.611069  140150100        0.0           0.0   \n",
       "21741  112.611069  140150100        0.0           0.0   \n",
       "21742  112.611069  140150100        0.0           0.0   \n",
       "21743  112.611069  140150100        0.0           0.0   \n",
       "\n",
       "                                                combined  \n",
       "0      Today's trades.Added to $AAPL at lows. Added t...  \n",
       "1      Using delta to calculate an option's leverage ...  \n",
       "2      Small Account (scalping trader) *Weekly Update...  \n",
       "3      Essential Properties Realty Trust Inc NYSE: EP...  \n",
       "4      Top 10 dividends survey (please read/upvote)Wo...  \n",
       "...                                                  ...  \n",
       "21739  Investing News Morning Roundup â€“ September 14,...  \n",
       "21740  Top 5 Things To Watch In The Stock Market This...  \n",
       "21741            Is $AAPL a good buy right now?[removed]  \n",
       "21742  $NVDA - street's initial take on $40b ARM acqu...  \n",
       "21743  $NVDA - street's initial take on $40b ARM acqu...  \n",
       "\n",
       "[21744 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a dataset for APPLE\n",
    "apple_df1=merged_df[merged_df['stock_symbol'] == 'aapl']\n",
    "apple_df1 = apple_df1.dropna(subset=['selftext'])\n",
    "\n",
    "apple_df1.rename(columns={'created_utc': 'Date'}, inplace=True)\n",
    "apple_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\data\\AAPL.csv\")\n",
    "\n",
    "#Correct date format\n",
    "apple_df['Date'] = pd.to_datetime(apple_df['Date'], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "apple_df['Date'] = apple_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "apple_df['Date'] = apple_df['Date'].dt.date\n",
    "\n",
    "apple_df_filtered = apple_df[(apple_df['Date'] >= pd.to_datetime('2018-01-01').date()) & \n",
    "                             (apple_df['Date'] <= pd.to_datetime('2022-12-31').date())]\n",
    "\n",
    "\n",
    "\n",
    "#Merging and creating\n",
    "apple_df1['Date'] = pd.to_datetime(apple_df1['Date'])\n",
    "apple_df_filtered['Date'] = pd.to_datetime(apple_df_filtered['Date'])\n",
    "merged_apple_df = pd.merge(apple_df1, apple_df_filtered, on='Date', how='inner')\n",
    "merged_apple_df['combined']=merged_apple_df['title']+merged_apple_df['selftext']\n",
    "merged_apple_df=merged_apple_df.drop(columns= ['title', 'selftext'])\n",
    "\n",
    "merged_apple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d7a3b2-617a-4864-8220-97a800ae1770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id stock_symbol       Date        Open        High         Low  \\\n",
      "0  pq28pz         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
      "1  pq2idf         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
      "2  pq3qvu         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
      "3  pq5pav         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
      "4  pq775d         aapl 2021-09-17  146.208137  146.208137  143.201829   \n",
      "\n",
      "        Close     Volume  Dividends  Stock Splits  \\\n",
      "0  143.496567  129868800        0.0           0.0   \n",
      "1  143.496567  129868800        0.0           0.0   \n",
      "2  143.496567  129868800        0.0           0.0   \n",
      "3  143.496567  129868800        0.0           0.0   \n",
      "4  143.496567  129868800        0.0           0.0   \n",
      "\n",
      "                                            combined  positive  negative  \\\n",
      "0  Today's trades.Added to $AAPL at lows. Added t...     0.000     0.124   \n",
      "1  Using delta to calculate an option's leverage ...     0.100     0.035   \n",
      "2  Small Account (scalping trader) *Weekly Update...     0.131     0.043   \n",
      "3  Essential Properties Realty Trust Inc NYSE: EP...     0.297     0.026   \n",
      "4  Top 10 dividends survey (please read/upvote)Wo...     0.092     0.000   \n",
      "\n",
      "   neutral  compound  \n",
      "0    0.876   -0.6204  \n",
      "1    0.865    0.9790  \n",
      "2    0.826    0.9991  \n",
      "3    0.677    0.9905  \n",
      "4    0.908    0.6249  \n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return {'pos': 0.0, 'neg': 0.0, 'neu': 0.0, 'compound': 0.0}  # Default sentiment scores for NaN\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply the function to get sentiment scores\n",
    "sentiment_scores = merged_apple_df['combined'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each sentiment score\n",
    "merged_apple_df['positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "merged_apple_df['negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "merged_apple_df['neutral'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "merged_apple_df['compound'] = sentiment_scores.apply(lambda x: x['compound'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462e0bcd-3be7-40a8-ad1e-28d8ea6f9072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>avg_positive</th>\n",
       "      <th>avg_negative</th>\n",
       "      <th>avg_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>146.208137</td>\n",
       "      <td>143.201829</td>\n",
       "      <td>143.496567</td>\n",
       "      <td>129868800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107727</td>\n",
       "      <td>0.028773</td>\n",
       "      <td>0.863500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>141.276212</td>\n",
       "      <td>142.297953</td>\n",
       "      <td>138.790616</td>\n",
       "      <td>140.431305</td>\n",
       "      <td>123478900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090208</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>0.872458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>147.986371</td>\n",
       "      <td>148.762499</td>\n",
       "      <td>146.139361</td>\n",
       "      <td>146.925323</td>\n",
       "      <td>102404300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093242</td>\n",
       "      <td>0.029697</td>\n",
       "      <td>0.877152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-15</td>\n",
       "      <td>145.952692</td>\n",
       "      <td>146.817252</td>\n",
       "      <td>143.801125</td>\n",
       "      <td>146.414444</td>\n",
       "      <td>83281300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082033</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.893567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>145.834786</td>\n",
       "      <td>146.355483</td>\n",
       "      <td>144.636197</td>\n",
       "      <td>146.178635</td>\n",
       "      <td>68034100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>0.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21461</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>111.839905</td>\n",
       "      <td>112.484182</td>\n",
       "      <td>107.378804</td>\n",
       "      <td>109.331146</td>\n",
       "      <td>180860300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090381</td>\n",
       "      <td>0.048786</td>\n",
       "      <td>0.860738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21468</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>111.986320</td>\n",
       "      <td>113.167486</td>\n",
       "      <td>110.112074</td>\n",
       "      <td>112.611069</td>\n",
       "      <td>140150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094611</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>0.873556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21495</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>118.390009</td>\n",
       "      <td>118.653579</td>\n",
       "      <td>115.978866</td>\n",
       "      <td>116.183861</td>\n",
       "      <td>115393800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078840</td>\n",
       "      <td>0.040160</td>\n",
       "      <td>0.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21557</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>113.616528</td>\n",
       "      <td>113.772719</td>\n",
       "      <td>111.556806</td>\n",
       "      <td>112.298698</td>\n",
       "      <td>82572600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083520</td>\n",
       "      <td>0.046160</td>\n",
       "      <td>0.870560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21643</th>\n",
       "      <td>aapl</td>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>115.510291</td>\n",
       "      <td>115.998376</td>\n",
       "      <td>110.902764</td>\n",
       "      <td>112.786774</td>\n",
       "      <td>184642000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>0.040974</td>\n",
       "      <td>0.866641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1252 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock_symbol       Date        Open        High         Low       Close  \\\n",
       "0             aapl 2021-09-17  146.208137  146.208137  143.201829  143.496567   \n",
       "11            aapl 2021-09-20  141.276212  142.297953  138.790616  140.431305   \n",
       "20            aapl 2021-09-13  147.986371  148.762499  146.139361  146.925323   \n",
       "26            aapl 2021-09-15  145.952692  146.817252  143.801125  146.414444   \n",
       "37            aapl 2021-09-16  145.834786  146.355483  144.636197  146.178635   \n",
       "...            ...        ...         ...         ...         ...         ...   \n",
       "21461         aapl 2020-09-11  111.839905  112.484182  107.378804  109.331146   \n",
       "21468         aapl 2020-09-14  111.986320  113.167486  110.112074  112.611069   \n",
       "21495         aapl 2020-10-16  118.390009  118.653579  115.978866  116.183861   \n",
       "21557         aapl 2020-10-23  113.616528  113.772719  111.556806  112.298698   \n",
       "21643         aapl 2020-09-15  115.510291  115.998376  110.902764  112.786774   \n",
       "\n",
       "          Volume  Dividends  Stock Splits  avg_positive  avg_negative  \\\n",
       "0      129868800        0.0           0.0      0.107727      0.028773   \n",
       "11     123478900        0.0           0.0      0.090208      0.037208   \n",
       "20     102404300        0.0           0.0      0.093242      0.029697   \n",
       "26      83281300        0.0           0.0      0.082033      0.024400   \n",
       "37      68034100        0.0           0.0      0.094222      0.032722   \n",
       "...          ...        ...           ...           ...           ...   \n",
       "21461  180860300        0.0           0.0      0.090381      0.048786   \n",
       "21468  140150100        0.0           0.0      0.094611      0.031944   \n",
       "21495  115393800        0.0           0.0      0.078840      0.040160   \n",
       "21557   82572600        0.0           0.0      0.083520      0.046160   \n",
       "21643  184642000        0.0           0.0      0.092359      0.040974   \n",
       "\n",
       "       avg_neutral  \n",
       "0         0.863500  \n",
       "11        0.872458  \n",
       "20        0.877152  \n",
       "26        0.893567  \n",
       "37        0.873000  \n",
       "...            ...  \n",
       "21461     0.860738  \n",
       "21468     0.873556  \n",
       "21495     0.881000  \n",
       "21557     0.870560  \n",
       "21643     0.866641  \n",
       "\n",
       "[1252 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "merged_apple_df['Date'] = pd.to_datetime(merged_apple_df['Date'])\n",
    "\n",
    "# Group by 'Date' to calculate total sentiment scores and post counts for each day\n",
    "daily_sentiments = merged_apple_df.groupby('Date').agg(\n",
    "    total_positive=('positive', 'sum'),\n",
    "    total_negative=('negative', 'sum'),\n",
    "    total_neutral=('neutral', 'sum'),\n",
    "    post_count=('positive', 'count')  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "daily_sentiments['avg_positive'] = daily_sentiments['total_positive'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_negative'] = daily_sentiments['total_negative'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_neutral'] = daily_sentiments['total_neutral'] / daily_sentiments['post_count']\n",
    "\n",
    "\n",
    "apple_final_df = pd.merge(merged_apple_df, daily_sentiments, on='Date', how='left')\n",
    "\n",
    "\n",
    "apple_final_df = apple_final_df.drop(\n",
    "    columns=['selftext', 'id', 'sentiment', 'positive', 'negative', 'neutral', 'compound','total_positive','total_negative','total_neutral','post_count','combined'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "apple_final_df = apple_final_df.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "apple_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8107193d-57c5-4cd5-aa45-dcc6f13041a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6412\\1368228589.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_df_filtered['Date'] = pd.to_datetime(tesla_df_filtered['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u7mi4n</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>343.333344</td>\n",
       "      <td>344.666656</td>\n",
       "      <td>325.083344</td>\n",
       "      <td>325.733337</td>\n",
       "      <td>70711200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$TSLA Q1'22 Earnings Thread ðŸŒ•Fun chat. No comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kabo1n</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>191.456665</td>\n",
       "      <td>209.250000</td>\n",
       "      <td>188.779999</td>\n",
       "      <td>209.023331</td>\n",
       "      <td>201249600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Does VIX seem just seem weirdly calm to anyone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b8y5a1</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>19.154667</td>\n",
       "      <td>19.744667</td>\n",
       "      <td>19.144667</td>\n",
       "      <td>19.454000</td>\n",
       "      <td>118791000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Why is TSLA shooting up? What does the market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ngb8em</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>184.183334</td>\n",
       "      <td>188.736664</td>\n",
       "      <td>182.326660</td>\n",
       "      <td>187.820007</td>\n",
       "      <td>118735200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>What's going on with TSLA[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k4y1iu</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>185.479996</td>\n",
       "      <td>190.513336</td>\n",
       "      <td>180.403336</td>\n",
       "      <td>189.606674</td>\n",
       "      <td>143327100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12/4 600c TSLA[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38683</th>\n",
       "      <td>pzhcjs</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>259.466675</td>\n",
       "      <td>260.260010</td>\n",
       "      <td>254.529999</td>\n",
       "      <td>258.406677</td>\n",
       "      <td>51094200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Let's SPIN the #Webull Wheel! 4000 shares of $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38684</th>\n",
       "      <td>zpqxon</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>155.250000</td>\n",
       "      <td>145.820007</td>\n",
       "      <td>149.869995</td>\n",
       "      <td>139390600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TSLA Terathread - For the week of Dec 19We lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38685</th>\n",
       "      <td>o5bfvw</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>206.083328</td>\n",
       "      <td>209.523331</td>\n",
       "      <td>205.166672</td>\n",
       "      <td>207.903336</td>\n",
       "      <td>57476700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$AMD Merger Incoming -- Breakout Catalyst (3-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38686</th>\n",
       "      <td>zps68h</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>155.250000</td>\n",
       "      <td>145.820007</td>\n",
       "      <td>149.869995</td>\n",
       "      <td>139390600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Options Questions Safe Haven Thread | Dec 18-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38687</th>\n",
       "      <td>zpreoo</td>\n",
       "      <td>tsla</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>155.250000</td>\n",
       "      <td>145.820007</td>\n",
       "      <td>149.869995</td>\n",
       "      <td>139390600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>morning breakdownThe S&amp;amp;P 500 futures are 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38688 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id stock_symbol       Date        Open        High         Low  \\\n",
       "0      u7mi4n         tsla 2022-04-20  343.333344  344.666656  325.083344   \n",
       "1      kabo1n         tsla 2020-12-10  191.456665  209.250000  188.779999   \n",
       "2      b8y5a1         tsla 2019-04-03   19.154667   19.744667   19.144667   \n",
       "3      ngb8em         tsla 2021-05-19  184.183334  188.736664  182.326660   \n",
       "4      k4y1iu         tsla 2020-12-02  185.479996  190.513336  180.403336   \n",
       "...       ...          ...        ...         ...         ...         ...   \n",
       "38683  pzhcjs         tsla 2021-10-01  259.466675  260.260010  254.529999   \n",
       "38684  zpqxon         tsla 2022-12-19  154.000000  155.250000  145.820007   \n",
       "38685  o5bfvw         tsla 2021-06-22  206.083328  209.523331  205.166672   \n",
       "38686  zps68h         tsla 2022-12-19  154.000000  155.250000  145.820007   \n",
       "38687  zpreoo         tsla 2022-12-19  154.000000  155.250000  145.820007   \n",
       "\n",
       "            Close     Volume  Dividends  Stock Splits  \\\n",
       "0      325.733337   70711200        0.0           0.0   \n",
       "1      209.023331  201249600        0.0           0.0   \n",
       "2       19.454000  118791000        0.0           0.0   \n",
       "3      187.820007  118735200        0.0           0.0   \n",
       "4      189.606674  143327100        0.0           0.0   \n",
       "...           ...        ...        ...           ...   \n",
       "38683  258.406677   51094200        0.0           0.0   \n",
       "38684  149.869995  139390600        0.0           0.0   \n",
       "38685  207.903336   57476700        0.0           0.0   \n",
       "38686  149.869995  139390600        0.0           0.0   \n",
       "38687  149.869995  139390600        0.0           0.0   \n",
       "\n",
       "                                                combined  \n",
       "0      $TSLA Q1'22 Earnings Thread ðŸŒ•Fun chat. No comm...  \n",
       "1      Does VIX seem just seem weirdly calm to anyone...  \n",
       "2      Why is TSLA shooting up? What does the market ...  \n",
       "3                     What's going on with TSLA[removed]  \n",
       "4                                12/4 600c TSLA[removed]  \n",
       "...                                                  ...  \n",
       "38683  Let's SPIN the #Webull Wheel! 4000 shares of $...  \n",
       "38684  TSLA Terathread - For the week of Dec 19We lau...  \n",
       "38685  $AMD Merger Incoming -- Breakout Catalyst (3-4...  \n",
       "38686  Options Questions Safe Haven Thread | Dec 18-2...  \n",
       "38687  morning breakdownThe S&amp;P 500 futures are 0...  \n",
       "\n",
       "[38688 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a dataset for Tesla\n",
    "tesla_df1=merged_df[merged_df['stock_symbol'] == 'tsla']\n",
    "tesla_df1 = tesla_df1.dropna(subset=['selftext'])\n",
    "\n",
    "tesla_df1.rename(columns={'created_utc': 'Date'}, inplace=True)\n",
    "tesla_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\data\\TSLA.csv\")\n",
    "\n",
    "#Correct date format\n",
    "tesla_df['Date'] = pd.to_datetime(tesla_df['Date'], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "tesla_df['Date'] = tesla_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "tesla_df['Date'] = tesla_df['Date'].dt.date\n",
    "\n",
    "tesla_df_filtered = tesla_df[(tesla_df['Date'] >= pd.to_datetime('2018-01-01').date()) & \n",
    "                             (tesla_df['Date'] <= pd.to_datetime('2022-12-31').date())]\n",
    "\n",
    "\n",
    "\n",
    "#Merging and creating\n",
    "tesla_df1['Date'] = pd.to_datetime(tesla_df1['Date'])\n",
    "tesla_df_filtered['Date'] = pd.to_datetime(tesla_df_filtered['Date'])\n",
    "merged_tesla_df = pd.merge(tesla_df1, tesla_df_filtered, on='Date', how='inner')\n",
    "merged_tesla_df['combined']=merged_tesla_df['title']+merged_tesla_df['selftext']\n",
    "merged_tesla_df=merged_tesla_df.drop(columns= ['title', 'selftext'])\n",
    "merged_tesla_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f57b7-ce95-4459-9bf2-a02a16a916f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return {'pos': 0.0, 'neg': 0.0, 'neu': 0.0, 'compound': 0.0}  # Default sentiment scores for NaN\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply the function to get sentiment scores\n",
    "sentiment_scores = merged_tesla_df['combined'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each sentiment score\n",
    "merged_tesla_df['positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "merged_tesla_df['negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "merged_tesla_df['neutral'] = sentiment_scores.apply(lambda x: x['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c5089-f171-444a-8d12-18fce6e7109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "merged_tesla_df['Date'] = pd.to_datetime(merged_tesla_df['Date'])\n",
    "\n",
    "# Group by 'Date' to calculate total sentiment scores and post counts for each day\n",
    "daily_sentiments = merged_tesla_df.groupby('Date').agg(\n",
    "    total_positive=('positive', 'sum'),\n",
    "    total_negative=('negative', 'sum'),\n",
    "    total_neutral=('neutral', 'sum'),\n",
    "    post_count=('positive', 'count')  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "daily_sentiments['avg_positive'] = daily_sentiments['total_positive'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_negative'] = daily_sentiments['total_negative'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_neutral'] = daily_sentiments['total_neutral'] / daily_sentiments['post_count']\n",
    "\n",
    "\n",
    "tesla_final_df = pd.merge(merged_tesla_df, daily_sentiments, on='Date', how='left')\n",
    "\n",
    "\n",
    "tesla_final_df = tesla_final_df.drop(\n",
    "    columns=['selftext', 'id', 'sentiment', 'positive', 'negative', 'neutral', 'compound','total_positive','total_negative','total_neutral','post_count','combined'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "tesla_final_df = tesla_final_df.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "tesla_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422ac0af-8a9b-45e8-b6b3-0a40b46be32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6412\\1825005474.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  netflix_df_filtered['Date'] = pd.to_datetime(netflix_df_filtered['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kexv0z</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>535.489990</td>\n",
       "      <td>526.440002</td>\n",
       "      <td>532.900024</td>\n",
       "      <td>3193400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stock Market News Today | FED Meeting News | S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e60d4q</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>308.429993</td>\n",
       "      <td>308.429993</td>\n",
       "      <td>303.269989</td>\n",
       "      <td>304.320007</td>\n",
       "      <td>3512100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WSB ETF $TONKS (a look at what you talked abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kexvhh</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>535.489990</td>\n",
       "      <td>526.440002</td>\n",
       "      <td>532.900024</td>\n",
       "      <td>3193400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stock Market News Today | FED Meeting News | S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwop2h</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>691.609985</td>\n",
       "      <td>691.739990</td>\n",
       "      <td>679.739990</td>\n",
       "      <td>682.020020</td>\n",
       "      <td>2012900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DD: $SONY is more than the sum of its parts an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s9bttx</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>400.429993</td>\n",
       "      <td>409.149994</td>\n",
       "      <td>379.989990</td>\n",
       "      <td>397.500000</td>\n",
       "      <td>58904300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dow Jones and SPY 21.01.2022 Good Morning....G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>8cqja7</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2018-04-16</td>\n",
       "      <td>315.989990</td>\n",
       "      <td>316.100006</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>307.779999</td>\n",
       "      <td>20307900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Market is officially killed by Orange manCheck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>q26dbk</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>606.940002</td>\n",
       "      <td>640.390015</td>\n",
       "      <td>606.890015</td>\n",
       "      <td>634.809998</td>\n",
       "      <td>9534300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rant and Penny Stock Unusual Option Activity 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>7svt6y</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>272.299988</td>\n",
       "      <td>260.230011</td>\n",
       "      <td>269.700012</td>\n",
       "      <td>15336400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Netflix Can Survive and Flourish Even Without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>7sn62v</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>250.880005</td>\n",
       "      <td>261.709991</td>\n",
       "      <td>249.309998</td>\n",
       "      <td>261.299988</td>\n",
       "      <td>17352400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1/24 - Wednesday Pre-Market Stock Movers &amp;amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>ey0ijl</td>\n",
       "      <td>nflx</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>347.239990</td>\n",
       "      <td>359.630005</td>\n",
       "      <td>346.279999</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>6670600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>What are your Monday Watchlists?I've got a few...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5675 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id stock_symbol       Date        Open        High         Low  \\\n",
       "0     kexv0z         nflx 2020-12-17  529.000000  535.489990  526.440002   \n",
       "1     e60d4q         nflx 2019-12-04  308.429993  308.429993  303.269989   \n",
       "2     kexvhh         nflx 2020-12-17  529.000000  535.489990  526.440002   \n",
       "3     qwop2h         nflx 2021-11-18  691.609985  691.739990  679.739990   \n",
       "4     s9bttx         nflx 2022-01-21  400.429993  409.149994  379.989990   \n",
       "...      ...          ...        ...         ...         ...         ...   \n",
       "5670  8cqja7         nflx 2018-04-16  315.989990  316.100006  304.000000   \n",
       "5671  q26dbk         nflx 2021-10-05  606.940002  640.390015  606.890015   \n",
       "5672  7svt6y         nflx 2018-01-25  263.000000  272.299988  260.230011   \n",
       "5673  7sn62v         nflx 2018-01-24  250.880005  261.709991  249.309998   \n",
       "5674  ey0ijl         nflx 2020-02-03  347.239990  359.630005  346.279999   \n",
       "\n",
       "           Close    Volume  Dividends  Stock Splits  \\\n",
       "0     532.900024   3193400        0.0           0.0   \n",
       "1     304.320007   3512100        0.0           0.0   \n",
       "2     532.900024   3193400        0.0           0.0   \n",
       "3     682.020020   2012900        0.0           0.0   \n",
       "4     397.500000  58904300        0.0           0.0   \n",
       "...          ...       ...        ...           ...   \n",
       "5670  307.779999  20307900        0.0           0.0   \n",
       "5671  634.809998   9534300        0.0           0.0   \n",
       "5672  269.700012  15336400        0.0           0.0   \n",
       "5673  261.299988  17352400        0.0           0.0   \n",
       "5674  358.000000   6670600        0.0           0.0   \n",
       "\n",
       "                                               combined  \n",
       "0     Stock Market News Today | FED Meeting News | S...  \n",
       "1     WSB ETF $TONKS (a look at what you talked abou...  \n",
       "2     Stock Market News Today | FED Meeting News | S...  \n",
       "3     DD: $SONY is more than the sum of its parts an...  \n",
       "4     Dow Jones and SPY 21.01.2022 Good Morning....G...  \n",
       "...                                                 ...  \n",
       "5670  Market is officially killed by Orange manCheck...  \n",
       "5671  Rant and Penny Stock Unusual Option Activity 1...  \n",
       "5672  Netflix Can Survive and Flourish Even Without ...  \n",
       "5673  1/24 - Wednesday Pre-Market Stock Movers &amp;...  \n",
       "5674  What are your Monday Watchlists?I've got a few...  \n",
       "\n",
       "[5675 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a dataset for netflix\n",
    "netflix_df1=merged_df[merged_df['stock_symbol'] == 'nflx']\n",
    "netflix_df1 = netflix_df1.dropna(subset=['selftext'])\n",
    "\n",
    "netflix_df1.rename(columns={'created_utc': 'Date'}, inplace=True)\n",
    "netflix_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\data\\NFLX.csv\")\n",
    "\n",
    "#Correct date format\n",
    "netflix_df['Date'] = pd.to_datetime(netflix_df['Date'], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "netflix_df['Date'] = netflix_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "netflix_df['Date'] = netflix_df['Date'].dt.date\n",
    "\n",
    "netflix_df_filtered = netflix_df[(netflix_df['Date'] >= pd.to_datetime('2018-01-01').date()) & \n",
    "                             (netflix_df['Date'] <= pd.to_datetime('2022-12-31').date())]\n",
    "\n",
    "\n",
    "\n",
    "#Merging and creating\n",
    "netflix_df1['Date'] = pd.to_datetime(netflix_df1['Date'])\n",
    "netflix_df_filtered['Date'] = pd.to_datetime(netflix_df_filtered['Date'])\n",
    "merged_netflix_df = pd.merge(netflix_df1, netflix_df_filtered, on='Date', how='inner')\n",
    "merged_netflix_df['combined']=merged_netflix_df['title']+merged_netflix_df['selftext']\n",
    "merged_netflix_df=merged_netflix_df.drop(columns= ['title', 'selftext'])\n",
    "merged_netflix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e32c786-5dc7-4f03-a46a-068d7dd37213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return {'pos': 0.0, 'neg': 0.0, 'neu': 0.0, 'compound': 0.0}  # Default sentiment scores for NaN\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply the function to get sentiment scores\n",
    "sentiment_scores = merged_netflix_df['combined'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each sentiment score\n",
    "merged_netflix_df['positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "merged_netflix_df['negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "merged_netflix_df['neutral'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d75fda28-635d-4dab-af1f-93dfd3c11185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>avg_positive</th>\n",
       "      <th>avg_negative</th>\n",
       "      <th>avg_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>535.489990</td>\n",
       "      <td>526.440002</td>\n",
       "      <td>532.900024</td>\n",
       "      <td>3193400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094875</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.871250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>308.429993</td>\n",
       "      <td>308.429993</td>\n",
       "      <td>303.269989</td>\n",
       "      <td>304.320007</td>\n",
       "      <td>3512100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>691.609985</td>\n",
       "      <td>691.739990</td>\n",
       "      <td>679.739990</td>\n",
       "      <td>682.020020</td>\n",
       "      <td>2012900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134333</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>400.429993</td>\n",
       "      <td>409.149994</td>\n",
       "      <td>379.989990</td>\n",
       "      <td>397.500000</td>\n",
       "      <td>58904300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097474</td>\n",
       "      <td>0.065860</td>\n",
       "      <td>0.836632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>426.950012</td>\n",
       "      <td>427.100006</td>\n",
       "      <td>418.049988</td>\n",
       "      <td>421.970001</td>\n",
       "      <td>4316000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.915500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5612</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>370.260010</td>\n",
       "      <td>370.260010</td>\n",
       "      <td>363.170013</td>\n",
       "      <td>365.359985</td>\n",
       "      <td>6768100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5613</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>515.239990</td>\n",
       "      <td>523.380005</td>\n",
       "      <td>512.299988</td>\n",
       "      <td>517.919983</td>\n",
       "      <td>2032800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2018-09-27</td>\n",
       "      <td>379.869995</td>\n",
       "      <td>383.200012</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>380.709991</td>\n",
       "      <td>7326200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>586.429993</td>\n",
       "      <td>602.880005</td>\n",
       "      <td>584.260010</td>\n",
       "      <td>593.739990</td>\n",
       "      <td>3358400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.808500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>nflx</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>347.239990</td>\n",
       "      <td>359.630005</td>\n",
       "      <td>346.279999</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>6670600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_symbol       Date        Open        High         Low       Close  \\\n",
       "0            nflx 2020-12-17  529.000000  535.489990  526.440002  532.900024   \n",
       "1            nflx 2019-12-04  308.429993  308.429993  303.269989  304.320007   \n",
       "3            nflx 2021-11-18  691.609985  691.739990  679.739990  682.020020   \n",
       "4            nflx 2022-01-21  400.429993  409.149994  379.989990  397.500000   \n",
       "5            nflx 2020-06-03  426.950012  427.100006  418.049988  421.970001   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "5612         nflx 2018-09-20  370.260010  370.260010  363.170013  365.359985   \n",
       "5613         nflx 2021-08-16  515.239990  523.380005  512.299988  517.919983   \n",
       "5624         nflx 2018-09-27  379.869995  383.200012  376.000000  380.709991   \n",
       "5647         nflx 2021-12-20  586.429993  602.880005  584.260010  593.739990   \n",
       "5674         nflx 2020-02-03  347.239990  359.630005  346.279999  358.000000   \n",
       "\n",
       "        Volume  Dividends  Stock Splits  avg_positive  avg_negative  \\\n",
       "0      3193400        0.0           0.0      0.094875      0.033875   \n",
       "1      3512100        0.0           0.0      0.067200      0.069800   \n",
       "3      2012900        0.0           0.0      0.134333      0.036667   \n",
       "4     58904300        0.0           0.0      0.097474      0.065860   \n",
       "5      4316000        0.0           0.0      0.000000      0.084500   \n",
       "...        ...        ...           ...           ...           ...   \n",
       "5612   6768100        0.0           0.0      0.168000      0.041000   \n",
       "5613   2032800        0.0           0.0      0.120000      0.043000   \n",
       "5624   7326200        0.0           0.0      0.094000      0.025000   \n",
       "5647   3358400        0.0           0.0      0.183000      0.008500   \n",
       "5674   6670600        0.0           0.0      0.273000      0.051000   \n",
       "\n",
       "      avg_neutral  \n",
       "0        0.871250  \n",
       "1        0.863600  \n",
       "3        0.829000  \n",
       "4        0.836632  \n",
       "5        0.915500  \n",
       "...           ...  \n",
       "5612     0.791000  \n",
       "5613     0.837000  \n",
       "5624     0.881000  \n",
       "5647     0.808500  \n",
       "5674     0.676000  \n",
       "\n",
       "[1120 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "merged_netflix_df['Date'] = pd.to_datetime(merged_netflix_df['Date'])\n",
    "\n",
    "# Group by 'Date' to calculate total sentiment scores and post counts for each day\n",
    "daily_sentiments = merged_netflix_df.groupby('Date').agg(\n",
    "    total_positive=('positive', 'sum'),\n",
    "    total_negative=('negative', 'sum'),\n",
    "    total_neutral=('neutral', 'sum'),\n",
    "    post_count=('positive', 'count')  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "daily_sentiments['avg_positive'] = daily_sentiments['total_positive'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_negative'] = daily_sentiments['total_negative'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_neutral'] = daily_sentiments['total_neutral'] / daily_sentiments['post_count']\n",
    "\n",
    "\n",
    "netflix_final_df = pd.merge(merged_netflix_df, daily_sentiments, on='Date', how='left')\n",
    "\n",
    "\n",
    "netflix_final_df = netflix_final_df.drop(\n",
    "    columns=['selftext', 'id', 'sentiment', 'positive', 'negative', 'neutral', 'compound','total_positive','total_negative','total_neutral','post_count','combined'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "netflix_final_df = netflix_final_df.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "netflix_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe21c40-125e-4eff-94da-e873cc505464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6412\\267056890.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nividia_df_filtered['Date'] = pd.to_datetime(nividia_df_filtered['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aknx1k</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>3.386507</td>\n",
       "      <td>3.512741</td>\n",
       "      <td>3.248864</td>\n",
       "      <td>3.422715</td>\n",
       "      <td>2511528000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NVDA and AMDRight now (9:20 am) AMD is tanking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhtm99</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2021-05-21</td>\n",
       "      <td>15.131626</td>\n",
       "      <td>15.189753</td>\n",
       "      <td>14.838000</td>\n",
       "      <td>14.959991</td>\n",
       "      <td>672992000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$NVDA split![removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pjtfbo</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>22.793868</td>\n",
       "      <td>22.859755</td>\n",
       "      <td>22.483400</td>\n",
       "      <td>22.623161</td>\n",
       "      <td>198107000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THE WORLD IS HUNGRY FOR CHIPS - Undervalued Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r7h092</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>31.164316</td>\n",
       "      <td>32.426304</td>\n",
       "      <td>30.975616</td>\n",
       "      <td>32.074863</td>\n",
       "      <td>472890000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FTC sues to block Nvidiaâ€™s $40 billion acquisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tnk0ur</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>27.846358</td>\n",
       "      <td>28.317687</td>\n",
       "      <td>27.232233</td>\n",
       "      <td>27.652634</td>\n",
       "      <td>579016000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fri Mar 25 22:39:43 2022NASDAQ:TLRY / 136\\n\\n[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>f7crcv</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>7.573524</td>\n",
       "      <td>7.598670</td>\n",
       "      <td>7.236663</td>\n",
       "      <td>7.321563</td>\n",
       "      <td>768180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The two largest institutions in the US have $5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>aphvdm</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>3.630544</td>\n",
       "      <td>3.684857</td>\n",
       "      <td>3.583671</td>\n",
       "      <td>3.632032</td>\n",
       "      <td>495180000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NVDAI have 7 shares that are KILLING ME. Bough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941</th>\n",
       "      <td>8bagjy</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>5.561112</td>\n",
       "      <td>5.667028</td>\n",
       "      <td>5.503946</td>\n",
       "      <td>5.640054</td>\n",
       "      <td>761676000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zuck won't stop saying AINVDA to the moon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>utfh6x</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>16.912925</td>\n",
       "      <td>17.661858</td>\n",
       "      <td>16.710212</td>\n",
       "      <td>17.099659</td>\n",
       "      <td>621310000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Las 10 Mejores Acciones De Inteligencia Artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9943</th>\n",
       "      <td>i8l8yz</td>\n",
       "      <td>nvda</td>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>10.957166</td>\n",
       "      <td>11.431960</td>\n",
       "      <td>10.924765</td>\n",
       "      <td>11.405293</td>\n",
       "      <td>464412000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/r/stocks - Top Trending Data on 2020-08-12##T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9944 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id stock_symbol       Date       Open       High        Low  \\\n",
       "0     aknx1k         nvda 2019-01-28   3.386507   3.512741   3.248864   \n",
       "1     nhtm99         nvda 2021-05-21  15.131626  15.189753  14.838000   \n",
       "2     pjtfbo         nvda 2021-09-07  22.793868  22.859755  22.483400   \n",
       "3     r7h092         nvda 2021-12-02  31.164316  32.426304  30.975616   \n",
       "4     tnk0ur         nvda 2022-03-25  27.846358  28.317687  27.232233   \n",
       "...      ...          ...        ...        ...        ...        ...   \n",
       "9939  f7crcv         nvda 2020-02-21   7.573524   7.598670   7.236663   \n",
       "9940  aphvdm         nvda 2019-02-11   3.630544   3.684857   3.583671   \n",
       "9941  8bagjy         nvda 2018-04-10   5.561112   5.667028   5.503946   \n",
       "9942  utfh6x         nvda 2022-05-19  16.912925  17.661858  16.710212   \n",
       "9943  i8l8yz         nvda 2020-08-12  10.957166  11.431960  10.924765   \n",
       "\n",
       "          Close      Volume  Dividends  Stock Splits  \\\n",
       "0      3.422715  2511528000        0.0           0.0   \n",
       "1     14.959991   672992000        0.0           0.0   \n",
       "2     22.623161   198107000        0.0           0.0   \n",
       "3     32.074863   472890000        0.0           0.0   \n",
       "4     27.652634   579016000        0.0           0.0   \n",
       "...         ...         ...        ...           ...   \n",
       "9939   7.321563   768180000        0.0           0.0   \n",
       "9940   3.632032   495180000        0.0           0.0   \n",
       "9941   5.640054   761676000        0.0           0.0   \n",
       "9942  17.099659   621310000        0.0           0.0   \n",
       "9943  11.405293   464412000        0.0           0.0   \n",
       "\n",
       "                                               combined  \n",
       "0     NVDA and AMDRight now (9:20 am) AMD is tanking...  \n",
       "1                                 $NVDA split![removed]  \n",
       "2     THE WORLD IS HUNGRY FOR CHIPS - Undervalued Se...  \n",
       "3     FTC sues to block Nvidiaâ€™s $40 billion acquisi...  \n",
       "4     Fri Mar 25 22:39:43 2022NASDAQ:TLRY / 136\\n\\n[...  \n",
       "...                                                 ...  \n",
       "9939  The two largest institutions in the US have $5...  \n",
       "9940  NVDAI have 7 shares that are KILLING ME. Bough...  \n",
       "9941          Zuck won't stop saying AINVDA to the moon  \n",
       "9942  Las 10 Mejores Acciones De Inteligencia Artifi...  \n",
       "9943  /r/stocks - Top Trending Data on 2020-08-12##T...  \n",
       "\n",
       "[9944 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a dataset for nividia\n",
    "nividia_df1=merged_df[merged_df['stock_symbol'] == 'nvda']\n",
    "nividia_df1 = nividia_df1.dropna(subset=['selftext'])\n",
    "\n",
    "nividia_df1.rename(columns={'created_utc': 'Date'}, inplace=True)\n",
    "nividia_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\data\\NVDA.csv\")\n",
    "\n",
    "#Correct date format\n",
    "nividia_df['Date'] = pd.to_datetime(nividia_df['Date'], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "nividia_df['Date'] = nividia_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "nividia_df['Date'] = nividia_df['Date'].dt.date\n",
    "\n",
    "nividia_df_filtered = nividia_df[(nividia_df['Date'] >= pd.to_datetime('2018-01-01').date()) & \n",
    "                             (nividia_df['Date'] <= pd.to_datetime('2022-12-31').date())]\n",
    "\n",
    "\n",
    "\n",
    "#Merging and creating\n",
    "nividia_df1['Date'] = pd.to_datetime(nividia_df1['Date'])\n",
    "nividia_df_filtered['Date'] = pd.to_datetime(nividia_df_filtered['Date'])\n",
    "merged_nividia_df = pd.merge(nividia_df1, nividia_df_filtered, on='Date', how='inner')\n",
    "merged_nividia_df['combined']=merged_nividia_df['title']+merged_nividia_df['selftext']\n",
    "merged_nividia_df=merged_nividia_df.drop(columns= ['title', 'selftext'])\n",
    "merged_nividia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0801f34b-4e6b-4545-b711-3ea2a40c1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return {'pos': 0.0, 'neg': 0.0, 'neu': 0.0, 'compound': 0.0}  # Default sentiment scores for NaN\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply the function to get sentiment scores\n",
    "sentiment_scores = merged_nividia_df['combined'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each sentiment score\n",
    "merged_nividia_df['positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "merged_nividia_df['negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "merged_nividia_df['neutral'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6959d1a1-cb50-43c3-929d-25857f45aafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>avg_positive</th>\n",
       "      <th>avg_negative</th>\n",
       "      <th>avg_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>3.386507</td>\n",
       "      <td>3.512741</td>\n",
       "      <td>3.248864</td>\n",
       "      <td>3.422715</td>\n",
       "      <td>2511528000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.061714</td>\n",
       "      <td>0.895286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2021-05-21</td>\n",
       "      <td>15.131626</td>\n",
       "      <td>15.189753</td>\n",
       "      <td>14.838000</td>\n",
       "      <td>14.959991</td>\n",
       "      <td>672992000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077444</td>\n",
       "      <td>0.021111</td>\n",
       "      <td>0.901333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>22.793868</td>\n",
       "      <td>22.859755</td>\n",
       "      <td>22.483400</td>\n",
       "      <td>22.623161</td>\n",
       "      <td>198107000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075154</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.888923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>31.164316</td>\n",
       "      <td>32.426304</td>\n",
       "      <td>30.975616</td>\n",
       "      <td>32.074863</td>\n",
       "      <td>472890000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078933</td>\n",
       "      <td>0.033467</td>\n",
       "      <td>0.887467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>27.846358</td>\n",
       "      <td>28.317687</td>\n",
       "      <td>27.232233</td>\n",
       "      <td>27.652634</td>\n",
       "      <td>579016000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.840313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9808</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>13.412911</td>\n",
       "      <td>13.555766</td>\n",
       "      <td>13.254599</td>\n",
       "      <td>13.552774</td>\n",
       "      <td>233484000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>4.150435</td>\n",
       "      <td>4.153168</td>\n",
       "      <td>3.992112</td>\n",
       "      <td>4.021441</td>\n",
       "      <td>290968000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>6.289587</td>\n",
       "      <td>6.385417</td>\n",
       "      <td>6.280920</td>\n",
       "      <td>6.379226</td>\n",
       "      <td>421968000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>4.297323</td>\n",
       "      <td>4.367909</td>\n",
       "      <td>4.281664</td>\n",
       "      <td>4.365921</td>\n",
       "      <td>428176000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>nvda</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>13.864664</td>\n",
       "      <td>13.944942</td>\n",
       "      <td>13.369783</td>\n",
       "      <td>13.460532</td>\n",
       "      <td>298068000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.900400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stock_symbol       Date       Open       High        Low      Close  \\\n",
       "0            nvda 2019-01-28   3.386507   3.512741   3.248864   3.422715   \n",
       "1            nvda 2021-05-21  15.131626  15.189753  14.838000  14.959991   \n",
       "2            nvda 2021-09-07  22.793868  22.859755  22.483400  22.623161   \n",
       "3            nvda 2021-12-02  31.164316  32.426304  30.975616  32.074863   \n",
       "4            nvda 2022-03-25  27.846358  28.317687  27.232233  27.652634   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "9808         nvda 2020-10-23  13.412911  13.555766  13.254599  13.552774   \n",
       "9861         nvda 2019-08-27   4.150435   4.153168   3.992112   4.021441   \n",
       "9864         nvda 2018-06-01   6.289587   6.385417   6.280920   6.379226   \n",
       "9872         nvda 2019-07-23   4.297323   4.367909   4.281664   4.365921   \n",
       "9897         nvda 2020-10-19  13.864664  13.944942  13.369783  13.460532   \n",
       "\n",
       "          Volume  Dividends  Stock Splits  avg_positive  avg_negative  \\\n",
       "0     2511528000        0.0           0.0      0.043000      0.061714   \n",
       "1      672992000        0.0           0.0      0.077444      0.021111   \n",
       "2      198107000        0.0           0.0      0.075154      0.035846   \n",
       "3      472890000        0.0           0.0      0.078933      0.033467   \n",
       "4      579016000        0.0           0.0      0.107937      0.051750   \n",
       "...          ...        ...           ...           ...           ...   \n",
       "9808   233484000        0.0           0.0      0.083500      0.023000   \n",
       "9861   290968000        0.0           0.0      0.023000      0.005000   \n",
       "9864   421968000        0.0           0.0      0.057500      0.151500   \n",
       "9872   428176000        0.0           0.0      0.167000      0.000000   \n",
       "9897   298068000        0.0           0.0      0.069800      0.029600   \n",
       "\n",
       "      avg_neutral  \n",
       "0        0.895286  \n",
       "1        0.901333  \n",
       "2        0.888923  \n",
       "3        0.887467  \n",
       "4        0.840313  \n",
       "...           ...  \n",
       "9808     0.893750  \n",
       "9861     0.971000  \n",
       "9864     0.791000  \n",
       "9872     0.833000  \n",
       "9897     0.900400  \n",
       "\n",
       "[1209 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "merged_nividia_df['Date'] = pd.to_datetime(merged_nividia_df['Date'])\n",
    "\n",
    "# Group by 'Date' to calculate total sentiment scores and post counts for each day\n",
    "daily_sentiments = merged_nividia_df.groupby('Date').agg(\n",
    "    total_positive=('positive', 'sum'),\n",
    "    total_negative=('negative', 'sum'),\n",
    "    total_neutral=('neutral', 'sum'),\n",
    "    post_count=('positive', 'count')  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "daily_sentiments['avg_positive'] = daily_sentiments['total_positive'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_negative'] = daily_sentiments['total_negative'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_neutral'] = daily_sentiments['total_neutral'] / daily_sentiments['post_count']\n",
    "\n",
    "\n",
    "nividia_final_df = pd.merge(merged_nividia_df, daily_sentiments, on='Date', how='left')\n",
    "\n",
    "\n",
    "nividia_final_df = nividia_final_df.drop(\n",
    "    columns=['selftext', 'id', 'sentiment', 'positive', 'negative', 'neutral', 'compound','total_positive','total_negative','total_neutral','post_count','combined'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "nividia_final_df = nividia_final_df.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "nividia_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c469c-f5a5-4db3-b07b-239e95fec30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "####NO STOCK PRICES WERE FOUND FOR MCD.csv#####\n",
    "\n",
    "# Creating a dataset for MCD\n",
    "MCD_df1=merged_df[merged_df['stock_symbol'] == 'mcd']\n",
    "MCD_df1 = MCD_df1.dropna(subset=['selftext'])\n",
    "\n",
    "MCD_df1.rename(columns={'created_utc': 'Date'}, inplace=True)\n",
    "MCD_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\data\\MCD.csv\")\n",
    "\n",
    "#Correct date format\n",
    "MCD_df['Date'] = pd.to_datetime(MCD_df['Date'], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "MCD_df['Date'] = MCD_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "MCD_df['Date'] = MCD_df['Date'].dt.date\n",
    "\n",
    "MCD_df_filtered = MCD_df[(MCD_df['Date'] >= pd.to_datetime('2018-01-01').date()) & \n",
    "                             (MCD_df['Date'] <= pd.to_datetime('2022-12-31').date())]\n",
    "\n",
    "\n",
    "\n",
    "#Merging and creating\n",
    "MCD_df1['Date'] = pd.to_datetime(MCD_df1['Date'])\n",
    "MCD_df_filtered['Date'] = pd.to_datetime(MCD_df_filtered['Date'])\n",
    "merged_MCD_df = pd.merge(MCD_df1, MCD_df_filtered, on='Date', how='inner')\n",
    "merged_MCD_df['combined']=merged_MCD_df['title']+merged_MCD_df['selftext']\n",
    "merged_MCD_df=merged_MCD_df.drop(columns= ['title', 'selftext'])\n",
    "merged_MCD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d97a4-c848-4bb8-a2b8-f612af223eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return {'pos': 0.0, 'neg': 0.0, 'neu': 0.0, 'compound': 0.0}  # Default sentiment scores for NaN\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply the function to get sentiment scores\n",
    "sentiment_scores = merged_MCD_df['combined'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each sentiment score\n",
    "merged_MCD_df['positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "merged_MCD_df['negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "merged_MCD_df['neutral'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81a0fe-f901-46bd-a188-6f318485603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "merged_MCD_df['Date'] = pd.to_datetime(merged_MCD_df['Date'])\n",
    "\n",
    "# Group by 'Date' to calculate total sentiment scores and post counts for each day\n",
    "daily_sentiments = merged_MCD_df.groupby('Date').agg(\n",
    "    total_positive=('positive', 'sum'),\n",
    "    total_negative=('negative', 'sum'),\n",
    "    total_neutral=('neutral', 'sum'),\n",
    "    post_count=('positive', 'count')  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "daily_sentiments['avg_positive'] = daily_sentiments['total_positive'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_negative'] = daily_sentiments['total_negative'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_neutral'] = daily_sentiments['total_neutral'] / daily_sentiments['post_count']\n",
    "\n",
    "\n",
    "MCD_final_df = pd.merge(merged_MCD_df, daily_sentiments, on='Date', how='left')\n",
    "\n",
    "\n",
    "MCD_final_df = MCD_final_df.drop(\n",
    "    columns=['selftext', 'id', 'sentiment', 'positive', 'negative', 'neutral', 'compound','total_positive','total_negative','total_neutral','post_count','combined'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "MCD_final_df = MCD_final_df.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "MCD_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e08224-1e3a-4672-a3b3-586cf8cb3eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6412\\1466687899.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  microsoft_df_filtered['Date'] = pd.to_datetime(microsoft_df_filtered['Date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euy99l</td>\n",
       "      <td>msft</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>156.966739</td>\n",
       "      <td>158.864367</td>\n",
       "      <td>156.286283</td>\n",
       "      <td>158.576859</td>\n",
       "      <td>24899900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long USDJPY[ES turning. Gap should fill](https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qfme6j</td>\n",
       "      <td>msft</td>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>301.591428</td>\n",
       "      <td>301.630431</td>\n",
       "      <td>298.764257</td>\n",
       "      <td>300.392334</td>\n",
       "      <td>17554500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Windows 10 - Attempting to Lock the Screen aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qfmep0</td>\n",
       "      <td>msft</td>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>301.591428</td>\n",
       "      <td>301.630431</td>\n",
       "      <td>298.764257</td>\n",
       "      <td>300.392334</td>\n",
       "      <td>17554500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Any good mega caps between 50bn and 200bnSo gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ev76zl</td>\n",
       "      <td>msft</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>156.966739</td>\n",
       "      <td>158.864367</td>\n",
       "      <td>156.286283</td>\n",
       "      <td>158.576859</td>\n",
       "      <td>24899900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>up 30K today on MSFT calls, but I am dumb and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ev6a87</td>\n",
       "      <td>msft</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>156.966739</td>\n",
       "      <td>158.864367</td>\n",
       "      <td>156.286283</td>\n",
       "      <td>158.576859</td>\n",
       "      <td>24899900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ultra Disk managed disks and MS SQL Server?Is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16325</th>\n",
       "      <td>p81j3k</td>\n",
       "      <td>msft</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>292.193454</td>\n",
       "      <td>298.159764</td>\n",
       "      <td>290.575136</td>\n",
       "      <td>296.716919</td>\n",
       "      <td>40817600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Why should you not buy MSFT?Hey! Iâ€˜m thinking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16326</th>\n",
       "      <td>ui7awm</td>\n",
       "      <td>msft</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>276.568331</td>\n",
       "      <td>284.681689</td>\n",
       "      <td>270.833215</td>\n",
       "      <td>283.800873</td>\n",
       "      <td>33599300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SEC database x EDGAR - fail to find Income Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16327</th>\n",
       "      <td>w1yz4z</td>\n",
       "      <td>msft</td>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>254.807112</td>\n",
       "      <td>255.876366</td>\n",
       "      <td>248.479855</td>\n",
       "      <td>249.411774</td>\n",
       "      <td>20975000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Netflix to report a loss of 2 million subscrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16328</th>\n",
       "      <td>b3vjhh</td>\n",
       "      <td>msft</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>111.103647</td>\n",
       "      <td>114.594013</td>\n",
       "      <td>111.056221</td>\n",
       "      <td>114.024933</td>\n",
       "      <td>29854400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Normal for entry level jobs now to have thousa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16329</th>\n",
       "      <td>klexla</td>\n",
       "      <td>msft</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>217.391710</td>\n",
       "      <td>218.922025</td>\n",
       "      <td>216.006686</td>\n",
       "      <td>217.885681</td>\n",
       "      <td>17933500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Good idea to keep DRIPing: ABBV, APPL, MSFT, T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16330 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id stock_symbol       Date        Open        High         Low  \\\n",
       "0      euy99l         msft 2020-01-28  156.966739  158.864367  156.286283   \n",
       "1      qfme6j         msft 2021-10-25  301.591428  301.630431  298.764257   \n",
       "2      qfmep0         msft 2021-10-25  301.591428  301.630431  298.764257   \n",
       "3      ev76zl         msft 2020-01-28  156.966739  158.864367  156.286283   \n",
       "4      ev6a87         msft 2020-01-28  156.966739  158.864367  156.286283   \n",
       "...       ...          ...        ...         ...         ...         ...   \n",
       "16325  p81j3k         msft 2021-08-20  292.193454  298.159764  290.575136   \n",
       "16326  ui7awm         msft 2022-05-04  276.568331  284.681689  270.833215   \n",
       "16327  w1yz4z         msft 2022-07-18  254.807112  255.876366  248.479855   \n",
       "16328  b3vjhh         msft 2019-03-21  111.103647  114.594013  111.056221   \n",
       "16329  klexla         msft 2020-12-28  217.391710  218.922025  216.006686   \n",
       "\n",
       "            Close    Volume  Dividends  Stock Splits  \\\n",
       "0      158.576859  24899900        0.0           0.0   \n",
       "1      300.392334  17554500        0.0           0.0   \n",
       "2      300.392334  17554500        0.0           0.0   \n",
       "3      158.576859  24899900        0.0           0.0   \n",
       "4      158.576859  24899900        0.0           0.0   \n",
       "...           ...       ...        ...           ...   \n",
       "16325  296.716919  40817600        0.0           0.0   \n",
       "16326  283.800873  33599300        0.0           0.0   \n",
       "16327  249.411774  20975000        0.0           0.0   \n",
       "16328  114.024933  29854400        0.0           0.0   \n",
       "16329  217.885681  17933500        0.0           0.0   \n",
       "\n",
       "                                                combined  \n",
       "0      Long USDJPY[ES turning. Gap should fill](https...  \n",
       "1      Windows 10 - Attempting to Lock the Screen aft...  \n",
       "2      Any good mega caps between 50bn and 200bnSo gu...  \n",
       "3      up 30K today on MSFT calls, but I am dumb and ...  \n",
       "4      Ultra Disk managed disks and MS SQL Server?Is ...  \n",
       "...                                                  ...  \n",
       "16325  Why should you not buy MSFT?Hey! Iâ€˜m thinking ...  \n",
       "16326  SEC database x EDGAR - fail to find Income Sta...  \n",
       "16327  Netflix to report a loss of 2 million subscrib...  \n",
       "16328  Normal for entry level jobs now to have thousa...  \n",
       "16329  Good idea to keep DRIPing: ABBV, APPL, MSFT, T...  \n",
       "\n",
       "[16330 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a dataset for microsoft\n",
    "microsoft_df1=merged_df[merged_df['stock_symbol'] == 'msft']\n",
    "microsoft_df1 = microsoft_df1.dropna(subset=['selftext'])\n",
    "\n",
    "microsoft_df1.rename(columns={'created_utc': 'Date'}, inplace=True)\n",
    "microsoft_df = pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\data\\MSFT.csv\")\n",
    "\n",
    "#Correct date format\n",
    "microsoft_df['Date'] = pd.to_datetime(microsoft_df['Date'], errors='coerce', utc=True)\n",
    "\n",
    "\n",
    "microsoft_df['Date'] = microsoft_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "microsoft_df['Date'] = microsoft_df['Date'].dt.date\n",
    "\n",
    "microsoft_df_filtered = microsoft_df[(microsoft_df['Date'] >= pd.to_datetime('2018-01-01').date()) & \n",
    "                             (microsoft_df['Date'] <= pd.to_datetime('2022-12-31').date())]\n",
    "\n",
    "\n",
    "\n",
    "#Merging and creating\n",
    "microsoft_df1['Date'] = pd.to_datetime(microsoft_df1['Date'])\n",
    "microsoft_df_filtered['Date'] = pd.to_datetime(microsoft_df_filtered['Date'])\n",
    "merged_microsoft_df = pd.merge(microsoft_df1, microsoft_df_filtered, on='Date', how='inner')\n",
    "merged_microsoft_df['combined']=merged_microsoft_df['title']+merged_microsoft_df['selftext']\n",
    "merged_microsoft_df=merged_microsoft_df.drop(columns= ['title', 'selftext'])\n",
    "merged_microsoft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f2531-239a-40fb-978b-ec9f1cc10252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return {'pos': 0.0, 'neg': 0.0, 'neu': 0.0, 'compound': 0.0}  # Default sentiment scores for NaN\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "# Apply the function to get sentiment scores\n",
    "sentiment_scores = merged_microsoft_df['combined'].apply(get_sentiment_scores)\n",
    "\n",
    "# Create separate columns for each sentiment score\n",
    "merged_microsoft_df['positive'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "merged_microsoft_df['negative'] = sentiment_scores.apply(lambda x: x['neg'])\n",
    "merged_microsoft_df['neutral'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3bb57-6ada-4852-9e72-dc8aa422eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "merged_microsoft_df['Date'] = pd.to_datetime(merged_microsoft_df['Date'])\n",
    "\n",
    "# Group by 'Date' to calculate total sentiment scores and post counts for each day\n",
    "daily_sentiments = merged_microsoft_df.groupby('Date').agg(\n",
    "    total_positive=('positive', 'sum'),\n",
    "    total_negative=('negative', 'sum'),\n",
    "    total_neutral=('neutral', 'sum'),\n",
    "    post_count=('positive', 'count')  \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "daily_sentiments['avg_positive'] = daily_sentiments['total_positive'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_negative'] = daily_sentiments['total_negative'] / daily_sentiments['post_count']\n",
    "daily_sentiments['avg_neutral'] = daily_sentiments['total_neutral'] / daily_sentiments['post_count']\n",
    "\n",
    "\n",
    "microsoft_final_df = pd.merge(merged_microsoft_df, daily_sentiments, on='Date', how='left')\n",
    "\n",
    "\n",
    "microsoft_final_df = microsoft_final_df.drop(\n",
    "    columns=['selftext', 'id', 'sentiment', 'positive', 'negative', 'neutral', 'compound','total_positive','total_negative','total_neutral','post_count','combined'], \n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "microsoft_final_df = microsoft_final_df.drop_duplicates(subset='Date')\n",
    "\n",
    "# Display the final DataFrame\n",
    "microsoft_final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035eb605-e6db-41da-b166-8add15a8197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395dee16-474d-4b7f-a251-215856ff6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161e42a-49d8-4150-8507-ab37228b5c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
